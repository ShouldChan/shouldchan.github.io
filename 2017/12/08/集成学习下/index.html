<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta name="viewport" content="width=932" >
  <meta name="MobileOptimized" content="932" >
  <meta name="generator" content="ShouldChan">
  <title>集成学习下</title>

  <link rel="stylesheet" type="text/css" href="/css/normalize.css">
  <link rel="stylesheet" type="text/css" href="/css/awe.css">
  <link rel="stylesheet" type="text/css" href="/css/social-likes.css">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="">

  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
  <script src="/js/imgLiquid-min.js"></script>
  <script src="/js/social-likes.min.js"></script>
</head>

<body>
  <div class="main-container">
    

<div class="box profile">
  <div class="heading" style="background: #3e5354 url(/images/bg-heading.jpg) no-repeat;">
    <div class="profile-img">
      <a href="//shouldchan.github.io/"><img src="/images/img-profile.jpg" width="154" height="150" alt="image description"></a>
    </div>
    <strong class="user"><a href="/">ShouldChan</a></strong>
    <span class="locate">Suzhou</span>
  </div>
  <div class="setting">
    <a href="//shouldchan.github.io/" class="btn-profile">Profile</a>
    <a href="/" class="btn-photos">Photos</a>
    <a href="/" class="btn-follow">Follow me</a>
  </div>
</div>

    
<div class="two-columns post-page">
  <div class="content">

    <div class="post box nocover">
      <em class="date"><span>08</span>Dec</em>
      <h2 class="post-title"><a href="/2017/12/08/集成学习下/">集成学习下</a></h2>
      <div class="post-content"><p>横跨快有两周的时间了，补一下集成学习下的内容。上上周写了集成学习上的博客，在那一块知识，有一个很典型的Boosting方法GDBT没有讲，之后会研究一番单独写一篇来表述一下。今天的主题就是Bagging和随机森林。这一部分内容在实验室seminar上是由大神Captain做的报告，这里会引用一些他使用的slide。</p>
<h1 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h1><p>Bagging的全称是Bootstrap AGGegratING。简单来说，bagging就是通过bootstrap取样（可重复取样）的方法来构造多个不同的数据集。之后在每个训练集上训练相应的基学习器，最后讲这些学习器集合起来得到最终的模型。<br>因此，bagging有两个重要组成部分（1）Bootstrap取样（2）模型聚合（aggregation）</p>
<h2 id="Bootstrap取样"><a href="#Bootstrap取样" class="headerlink" title="Bootstrap取样"></a>Bootstrap取样</h2><p>在集成学习上中有提到基学习器要具有多样性，虽然每个基学习器都会犯不同的错误，但是将他们聚合起来就有可能提升性能。<br>在给定一个训练集的情况下，如何尽可能地建立相对独立的基学习器呢？基本上我们只有两种选择：（1）在训练每个基学习器的时候使用不同的训练集；（2）在训练集相同或者相近的情况下，使用不同的学习算法来训练不同的基学习器。如果我们选择使用不同的训练集，一种可能性是将整个训练集划分为多个不同的子集，然后在每个子集上训练不同的基学习器。这个方法虽然保证了这些基学习器是从不同的训练集上得到的，但是由于每个子集都显著小于原来的训练集，使得构建的基学习器可能遗漏了原始训练集中的一些关键信息。同时，每个子集和整个训练集的分布可能存在差异。因此，这样得到的基学习器的性能会受到影响。<br>因此，既要利用训练集中更多的样本，又要同时尽量保证不同的训练集的独立性。我们采用Bootstrap取样法，就是可重复取样。<br>在这里，先补充一下Boosting中常用的重采样法（re-sampling）。就是指在每一轮的学习中，根据样本的分布来对训练集进行重新采样。比如说，一个班级里的学生身高是参差不齐，我们使用重采样法进行采样的话就是说在160-170里随机选一部分，在170-180里随机选一部分，在190以上那群人中选一部分，总结一下就是按照身高的分布选取相应的训练集。如果你使用Bootstrap的话，就存在取到只有170-190这个身高区间内的学生，没有取到低于170的学生样本。<br>解释完Re-sampling后，上一波Bootstrap教科书般的解释。bootstrap取样就是使用可重复取样（sampling with replacement）的方法，从样本数为n的数据集中取出n个样本。除了一种极端情况（就是bootstrap取样得到了整个原来的数据集），使用bootstrap取样得到的n个样本中都有重复样本，同时也有原来数据集中的样本没有被取到。注意，在可重复取样中，我们假设每个样本被选中的概率是一样的。在bagging中，对于原始的训练集，我们使用bootstrap取样m次，选取出m个样本集。在每个样本集上，我们构建相应的基学习器。这样就得到了m个不同的学习器。</p>
<h2 id="模型聚合"><a href="#模型聚合" class="headerlink" title="模型聚合"></a>模型聚合</h2><p>这一块其实就是集成学习上中提到的结合策略，第一使用投票法（majority voting），第二使用有权重的投票（weighted voting），第三使用Stacking。<br>在bagging中，我们通常使用比较简单的方法来聚合多个模型。<br>（1）对于分类问题，使用投票法。<br>（2）对于回归问题，使用平均法，直接取m个基学习器的输出的平均值即可。</p>
<h2 id="Bagging框架"><a href="#Bagging框架" class="headerlink" title="Bagging框架"></a>Bagging框架</h2><p>如图，通过bootstrap取样喂给学习器1，接着再取样喂给学习器2，一共取样m次每次喂给各个基学习器。从中，我们可以发现：bagging具有并行处理的优点。<br><img src="https://raw.githubusercontent.com/ShouldChan/ImageStore/master/blog_image/bagging_1.jpg" alt="Bagging框架（bagging_1）"></p>
<h2 id="Bagging优点"><a href="#Bagging优点" class="headerlink" title="Bagging优点"></a>Bagging优点</h2><p>除了刚刚谈到的并行处理，bagging还有另一个优点：对于每个基学习器，我们可以利用不在训练集的样本（out-of-bag sample，OOB样本）来估计基学习器的性能。在训练模型的过程中，由于我们从未接触过OOB样本，因此它们是天然的检验算法性能的数据。</p>
<h2 id="OOB"><a href="#OOB" class="headerlink" title="OOB"></a>OOB</h2><p>（1）用来帮助避免过拟合，决策树模型可以用来辅助剪枝，神经网络模型可以用来辅助早期停止。<br>（2）用来进行泛化误差的估计，可以对的那个样本x进行包外预测，也可以对训练集的所有样本通过包外预测进行性能度量。</p>
<h2 id="Bagging与Boosting的区别"><a href="#Bagging与Boosting的区别" class="headerlink" title="Bagging与Boosting的区别"></a>Bagging与Boosting的区别</h2><p>这里我们直接使用大神Captian总结的slide给出两者区别。<br><img src="https://raw.githubusercontent.com/ShouldChan/ImageStore/master/blog_image/bagging_2.jpg" alt="Bagging与Boosting的区别（bagging_2）"></p>
<h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><p>随机森林使用了bagging的基本思想来训练一系列决策树，并且在构建决策树时尽量降低决策树之间的相关性。</p>
<h2 id="RF算法"><a href="#RF算法" class="headerlink" title="RF算法"></a>RF算法</h2><p>如图给出RF算法，就不多做文字解释了。<br><img src="https://raw.githubusercontent.com/ShouldChan/ImageStore/master/blog_image/bagging_3.jpg" alt="随机森林算法（bagging_3）"></p>
<h2 id="RF的参数选择"><a href="#RF的参数选择" class="headerlink" title="RF的参数选择"></a>RF的参数选择</h2><p>对于随机森林，较为重要的参数有：<br>第一，决策树的数目m。一般来说，上百颗决策树时必需的。随着变量的增加，要取得比较好的性能，我们就需要增加随机森林中决策树的个数。测试当前决策树的数目是否足够的简易方案，可以比较当前已经得到的所有决策树和其中一部分决策树，看他们的预测值是否有较大区别。<br>第二，每颗决策树的大小，由决策树叶节点所能包含的样本数的最大值决定。<br>第三，每次选取最佳变量时随机选取的变量数d1。<br>如图给出了d1的选择建议<br><img src="https://raw.githubusercontent.com/ShouldChan/ImageStore/master/blog_image/bagging_4.jpg" alt="d1选择建议（bagging_4）"></p>
<p>如下给出如何利用OOB样本来估计变量。<br><img src="https://raw.githubusercontent.com/ShouldChan/ImageStore/master/blog_image/bagging_5.jpg" alt="OOB样本来估计变量（bagging_5）"></p>
<h2 id="RF的优点"><a href="#RF的优点" class="headerlink" title="RF的优点"></a>RF的优点</h2><p>第一，能够构建复杂的非线性模型，在实际中效果好。<br>第二，当决策树的数目多时对参数不是太敏感。<br>第三，易于并行。<br>第四，能够使用OOB样本估计变量的重要性。</p>
</div>

      <div class="bottom-panel">
        <ul class="social-likes" data-url="/2017/12/08/集成学习下/">
          <li class="facebook" title="like"></li>
          <li class="twitter" title="twitte"></li>
          <li class="plusone" title="google"></li>
        </ul>
      </div>
    </div>
    
  </div>

  <div class="widgetarea">

    
    
<div class="tags widget">
  <h3 class="title">Tags</h3>
  <div style="text-align:center">
    
    <a class="button" href="/tags/Machine-Learning/">Machine Learning</a>
    
  </div>
  
</div>


<div class="tagcloud" id="fbox-tagcloud" style="margin:10px; display:none; overflow: hidden"><a href="/tags/Machine-Learning/" style="font-size: 12px;">Machine Learning</a></div>

    

    
      

<ul class="widget blogroll">
  <h3 class="title">Recent Post</h3>
  
    
    <li>
      <div class="text-holder">
        <h3 class="link-title"><a href="/2018/07/17/关于隐反馈的一些个人见解/">关于隐反馈的一些个人见解</a></h3>
        <p>关于隐反馈的一些个人见解显式反馈和隐式反馈的区别显式反馈中，矩阵中的每个元素1-5代表用户对物品的喜</p>
      </div>
    </li>
  
    
    <li>
      <div class="text-holder">
        <h3 class="link-title"><a href="/2017/12/08/集成学习下/">集成学习下</a></h3>
        <p>横跨快有两周的时间了，补一下集成学习下的内容。上上周写了集成学习上的博客，在那一块知识，有一个很典型</p>
      </div>
    </li>
  
    
    <li>
      <div class="text-holder">
        <h3 class="link-title"><a href="/2017/11/26/集成学习上/">集成学习上</a></h3>
        <p>周中在实验室seminar上做了一个有关集成学习的报告，趁周末有空，把集成学习的相关内容写个博客。我</p>
      </div>
    </li>
  
    
    <li>
      <div class="text-holder">
        <h3 class="link-title"><a href="/2017/11/07/奇异值分解/">奇异值分解</a></h3>
        <p>简介奇异值分解（Singular Value Decomposition，SVD）是矩阵分解的一种，</p>
      </div>
    </li>
  
    
    <li>
      <div class="text-holder">
        <h3 class="link-title"><a href="/2017/11/06/线性回归/">线性回归</a></h3>
        <p>线性回归线性回归是一种监督学习方法，可以被用来解决回归问题。它用一条直线或高维空间中的平面来拟合训练</p>
      </div>
    </li>
  
</ul>


    

  </div>
</div>


  </div>
  
<div class="footer">
  <div class="container">
    <a href="//github.com/kywk/hexo-theme-awe">AWE for hexo</a> inspired by <a href="http://goo.gl/H8OMRE">Awesome UI Kit</a>,
    ported by <a href="//kywk.github.io/">MooCow (Aka. kywk)</a>.
    
    &copy; 2018 Should Chan All Rights Reserved
    
  </div>
</div>

  <!-- disqus -->



<script>
$(document).ready(function() {
  $('.imgLiquid').imgLiquid({fill:true, fadeInTime:500});
});
</script>


<!-- fancybox -->
<link rel="stylesheet" href="/package/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
<script type="text/javascript" src="/package/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<script type="text/javascript">
(function($){
  $(".fancybox").fancybox();
  $(".various").fancybox({
    maxWidth  : 800,
    maxHeight : 600,
    fitToView : false,
    width   : '70%',
    height    : '70%',
    autoSize  : true,
    closeClick  : false,
    openEffect  : 'none',
    closeEffect : 'none'
  });
})(jQuery);
</script>

</body>
</html>
